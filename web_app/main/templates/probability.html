{% extends 'base.html' %}
{% block content %}
    {% include 'navbars/navbar_prob_ampl.html' %}
    <div class="container">
        <div class="row mt-5">
            <h2>Probability Distributions</h2>
            <div class="col-12">
                <h3>Discrete Probability Distribution Functions</h3>
                <p> 
                    Suppose that \(N(j)\) represents the number of people that are \(j\) years old in a room.
                    We cannot look inside the room but instead can call people out one at a time.
                    After asking them what their ages are we can plot the following histogram:
                </p>
                <div class="row mt-5">
                    <div class="col-sm">
                        <pre>
                            <code class="language-python">
    ages = [14,15,16,22,24,25]
    frequency = [1,1,3,2,2,5]
    plot(x=ages,y=frequency,vbars="True")</code>
                        </pre>
                    </div>
                    <div class="col-sm">
                        <img src="{{url_for('static', filename='temp1.png')}}" style="padding-bottom: 1em" width="300" height="300" alt="hist" align="center">
                    </div>
                </div>
                <p>
                    Note for instance that \(N(17)\) is zero while we see that:
                    \(N(14) = 1\), \(N(15) = 1\), \(N(16) = 3\), \(N(22) = 2\), \(N(24) = 2\), and \(N(25) = 5\)

                    The total number of people in a room is therefore:
                    \[N = \sum_{j=0}^{\infty} N(j)\]
                </p>
                <p>
                    We can then ask what is the probaility \(P(j)\) of selecting one person of age \(j\). Which in general is:
                    \[P(j) = \frac{N(j)}{N}\]
                    In particular, the sum of *all* probabilities is 1. We are certain to get someone of some age:
                    \[ \sum_{j=1}^{\infty} P(j) = 1\]
                </p>
                <p>
                    With this code snippet we show that the total probabillity does really sum to 1.

                    <div class="row mt-5">
                        <div class="col-sm">
                            <pre>
                                <code class="language-python">
    data = zip(ages,frequency)
    N = sum(frequency)
    sum = 0
    for age, freq in data:
        sum += freq/N</code>
                            </pre>
                        </div>
                        <div class="col-sm">
                            <pre class="output_code">
    data = {(22, 2),(25, 5),(16, 3),(15, 1),(14, 1),(24, 2)}
    N = 14
    sum = 0
    ... 
        sum = 1
                            </pre>
                        </div>
                    </div>    
                </p>
                <h4> What do we expect? </h4>
                <p>
                    If we want to think about what is the most probable age, we need to think about the age value that we <i>expect</i> to see when we call someone out from the room.
                    In quantum mechanics we denote this via the "bra" \(⟨\) and "ket" \(⟩\) symbols around our variable of interest:

                    \[ ⟨j⟩ \]

                    In general, we will write the 'expectation' value of \(j\) as:

                    \[ ⟨j⟩ = \frac{\sum j N(j)}{N} = \sum_{j=0}^{\infty} j P(j) \]

                    Notice that this expression can give us values that are not included in our original dataset. 
                    While this is numerically the same as the average value, in the context of quantum mechanics this is termed the <b>expectation value</b>.
                    It is mathematically equivalent to a weighted average.

                    We can extend this expression to also ask: what is the average of the squares of the age? We can write this as: 

                    \[ ⟨j^2⟩ = \frac{\sum j^2 N(j)}{N} = \sum_{j=0}^{\infty} j^2 P(j) \]

                    In general, we can also ask this question for any function of \(j\): 

                    \[ ⟨f(j)⟩ = \sum_{j=0}^{\infty} f(j) P(j) \]
                </p>
                <p>
                    With this code snippet we calculate the expectation value of ages and the square of the ages.

                <div class="row mt-5">
                    <div class="col-sm">
                        <pre>
                            <code class="language-python">
    E_j = 0
    for age, freq in data:
        E_j = E_j + (age)*freq/N
    E_j2 = 0
    for age, freq in data:
        E_j2 = E_j2 + (age**2)*freq/N </code>
                        </pre>
                    </div>
                    <div class="col-sm">
                        <pre class="output_code">
    E_j = 0
    ...
        E_j = 21.0
    E_j2 = 0
    ...
        E_j2 = 459.57142857142856
                        </pre>
                    </div>
                </div>

                </p>

                <h4>Characterizing the distribution</h4>
                <p>
                    It is also important to ask how a distribution looks. Take for example these two distributions:
                </p>
                <div class="row mt-5">
                    <div class="col-sm">
                        <pre>
                            <code class="language-python">
    x1, y1 = [4,5,6], [1,7,1]
    x2, y2 = [1,2,3,4,5,6,7,8,9], [1,1,1,1,2,1,1,1,1]
    plot(x=x1,y=y1,vbars="True")
    plot(x=x2,y=y2,vbars="True")</code>
                        </pre>
                    </div>
                    <div class="col-sm">
                        <img src="{{url_for('static', filename='temp2.png')}}" style="padding-bottom: 1em" width="540" height="300" alt="hist" align="center">
                    </div>
                </div>
                <p>
                    By visual inspection, we can determine that the graphs are both centered around the same value.
                    Thus, it is reasonable to say that we expect to obtain the same average.
                    We can measure the spread of each distribution with the variance, which we can write using our special notation as:
                    \[ \sigma^2  = ⟨j^2⟩ - ⟨j⟩^2 \]

                    This seems really simple because we can just calculate \(⟨j⟩^2\) and then \(⟨j^2⟩\) using the formulas from before and use it for the standard deviation:
                    \[ \sigma  = \sqrt{⟨j^2⟩ - ⟨j⟩^2} \]
                </p>
                <p>
                    With this code snippet we calculate the standard deviation of the two distributions.
                    <div class="row mt-5"> 
                        <div class="col-sm">
                            <pre>
                                <code class="language-python">
    N1, N2 = sum(y1), sum(y2)

    E1_j = 0
    for x,y in zip(x1,y1):
        E1_j = E1_j + (x)*y/N1
    E2_j = 0
    for x,y in zip(x2,y2):
        E2_j = E2_j + (x)*y/N2

    E1_j2 = 0
    for x,y in zip(x1,y1):
        E1_j2 = E1_j2 + (x**2)*y/N1
    E2_j2 = 0
    for x,y in zip(x2,y2):
        E2_j2 = E2_j2 + (x**2)*y/N2
    
    sigma_1 = sqrt(E1_j2 - E1_j**2)
    sigma_2 = sqrt(E2_j2 - E2_j**2)</code>
                            </pre>
                        </div>
                        <div class="col-sm">
                            <pre class="output_code">
    N1, N2 = 9, 10

    E1_j = 0
    ...
        E1_j = 5.0
    E2_j = 0
    ...
        E2_j = 5.0
    
    E1_j2 = 0
    ...
        E1_j2 = 25.222222
    E2_j2 = 0
    ...
        E2_j2 = 31
    
    sigma_1 = 0.47140452079103085
    sigma_2 = 2.449489742783178
                            </pre>
                        </div>
                    </div>

                </p>

            </div>
        </div>
        <div class="row mt-5">
            <div class="col-12">
            <h3>Continous Probability Distribution Functions</h3>
            <p>
                It is simple enough to generalize what we have learned to the continous case. What if we ask: 
            </p>
            <ul>
                <li>What is the probability that someone's age is exactly 21 years, 21 days, 21 minutes, and 21 seconds?</li>
                <li>What is the probability that someone's age is between 20 years and 364 days and 20 years?</li>
            </ul>
            <p>
                To be able to answer these questions we need to refer to infinitesimal intervals:
                The probability that the chosen value is between \(x\) and \(x+dx\)  is given by \(\rho(x)dx\)
            </p>
            <img src="{{url_for('static', filename='continous.png')}}" alt="Continous Distribution"  width="450" height="300" align="left">
            <p>
                The continous distribution is made from infinitesimally small \(dx\) elements that make up the line representing the function \(f(x)\).
                The important thing to note here is that this analogy extends to the other components of the distribution.
                The function \(\rho(x)\) is termed the <b>probability density</b>. The probability that \(x\) lies between \(a\) and \(b\) is thus given by the integral of \(\rho(x)\) for the interval \([a,b]\) 

                \[ P_{[a,b]} = \int_a^b \rho(x) dx \]
            </p>
            <p>
                Our investigation from the previous section is also applicable in this section in an straightforward way.
                The discrete summations are integrals and the discrete values that are summed become infinitesimal intervals. 

                \[\int_{-\infty}^\infty \rho(x) dx = 1, ⟨x⟩ = \int_{-\infty}^\infty x \rho(x) dx, ⟨f(x)⟩ = \int_{-\infty}^\infty f(x) \rho(x) dx\]
            </p>
            <h4>Units of the probability density function</h4>
            <p>
                We have to be careful to understand the units of \(\rho(x)\). If we look at the integral: 
                \[\int_{-\infty}^\infty \rho(x) dx = 1 \]
                We notice that the integration leads to a unitless quantity. Thus, we can deduce that \( \rho(x) dx \) must have no units.
                If \(dx\) has units of \(distance\) for example, then \(\rho(x)\) must have units of \(\frac{1}{distance}\)
            </p>
            </div>
        </div>
        <div class="row mt-5">
            <div class="col-12">
            <h3>Normalization</h3>
            <p>
                We have to be careful of the fact that \(\int_{-\infty}^\infty \rho(x) dx = 1\).
                This means that not every function that we can come up with can be a probability density function.
                In fact, this statement is a statement of <b>normalization</b>.
                It is analogous to the fact that the sum of all the probabilites in a discrete problem should add up to one. 

                Quantum mechanics enforces the normalization of the porbability density functions. So we have to learn to normalize functions
            </p>
            </div>
        </div>
        <div class="row mt-5">
            <h2>Problems</h2>
            <p>
                <ol>
                    <li>Compute \(⟨j⟩^2\) and then \(⟨j^2⟩\) from the ages problem above. Determine \(\Delta j \) for each \(j\)</li>
                    <li>
                        The needle on a car spedometer is loose and free to swing. When you flick it, it is equally likely to land between \(0\) and \(\pi\) and can bounce off a pin at \(3\pi/2\).
                        <ol type="a">
                            <li>What is the probability density \(\rho(\theta)\)? Graph it as a function of \(\theta\) from \(-\pi/2\) to \(3\pi/2\). Hint: \(\rho(x)\) is 0 in a section of the interval. Make sure that the total probability is 1.</li>
                            <li>Compute \(⟨\theta⟩\), \(⟨\theta⟩^2\) and \(\sigma\) for the distribution</li>
                        </ol>
                    </li>
                    <li>
                        Consider the following probability density function:
                        \[\rho(x)=A e^{-\lambda(x-a)^{2}}\]
                        <ol type="a">
                            <li>Determine \(A\)</li>
                            <li>Compute \(⟨x⟩\), \(⟨x⟩^2\) and \(\sigma\)</li>
                            <li>Sketch the graph of \(\rho(x)\)</li>
                        </ol>
                    </li>
                    <li>
                        Consider the following function named \(\Psi(x,t)\). We define \(|\Psi(x,t)|^2 =\Psi(x,t) \times \Psi(x,t)= \rho(x,t)\). At \(t=0\):
                        \[\Psi(x, 0)=\left\{\begin{array}{ll}
                        A x / a, & \text { if } 0 \leq x \leq a, \\
                        A(b-x) /(b-a), & \text { if } a \leq x \leq b, \\
                        0, & \text { otherwise }
                        \end{array}\right.\]
                        <ol type="a">
                            <li>Find \(A\) in terms of \(a\) and \(b\) to ensure normalization</li>
                            <li>What is the expectation value of \(x\) at \(t=0\)?</li>
                        </ol>
                    </li>
                </ol>
            </p>
        </div>

        <div class="row mt-5">
            <p>
                <em>References:</em>
                <ul>
                    <li>R. Shankar, Principles of quantum mechanics. New York u.a.: Plenum Pr, 1988. </li>
                    <li>D. J. Griffiths and D. F. Schroeter, Introduction to quantum mechanics. Cambridge: Cambridge University Press, 2019.</li>
                </ul>
            </p>
        </div>
        <nav aria-label="Page navigation example">
            <ul class="pagination">
              <li class="page-item"><a class="btn btn-secondary btn-lg active" role="button" style="background-color: #411038;"  href="{{ url_for('classical_LC') }}">Previous</a></li>
              <li class="page-item"><a class="btn btn-secondary btn-lg active" role="button" style="background-color: #411038;"  href="{{ url_for('prob_amplitude') }}">Next</a></li>
            </ul>
          </nav>
        <img src="{{url_for('static', filename='MIT_c.jpg')}}" alt="MIT" width="270" height="100" align="left">
        <img src="{{url_for('static', filename='eecs.png')}}" alt="EECS" width="auto" height="100" align="right"> 
    </div>

{% endblock %}